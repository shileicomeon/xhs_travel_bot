"""
å°çº¢ä¹¦MCPå®¢æˆ·ç«¯

ç”¨äºè°ƒç”¨å°çº¢ä¹¦MCPæœåŠ¡çš„å„ç§åŠŸèƒ½
"""

import os
import asyncio
from typing import List, Dict, Optional
from langchain_mcp_adapters.client import MultiServerMCPClient
from ..utils.logger import logger


class XhsMcpClient:
    """å°çº¢ä¹¦MCPå®¢æˆ·ç«¯"""
    
    def __init__(self):
        self.mcp_url = os.getenv("XHS_MCP_URL", "http://localhost:18060/mcp")
        self.transport = os.getenv("MCP_TRANSPORT", "http")
        self.client = None
        self.tools = None
    
    async def _ensure_connected(self):
        """ç¡®ä¿MCPå®¢æˆ·ç«¯å·²è¿æ¥"""
        if self.client is None:
            logger.info("è¿æ¥å°çº¢ä¹¦MCPæœåŠ¡...")
            self.client = MultiServerMCPClient({
                "xiaohongshu-mcp": {
                    "transport": self.transport,
                    "url": self.mcp_url,
                }
            })
            self.tools = await self.client.get_tools()
            logger.info(f"âœ… å·²è¿æ¥ï¼Œè·å–åˆ° {len(self.tools)} ä¸ªå·¥å…·")
    
    def _get_tool(self, tool_name: str):
        """è·å–æŒ‡å®šå·¥å…·"""
        if self.tools is None:
            raise RuntimeError("MCPå®¢æˆ·ç«¯æœªè¿æ¥")
        
        for tool in self.tools:
            if getattr(tool, "name", "") == tool_name:
                return tool
        
        raise ValueError(f"æœªæ‰¾åˆ°å·¥å…·: {tool_name}")
    
    async def check_login_status(self) -> Dict:
        """æ£€æŸ¥ç™»å½•çŠ¶æ€"""
        await self._ensure_connected()
        
        logger.info("æ£€æŸ¥å°çº¢ä¹¦ç™»å½•çŠ¶æ€...")
        tool = self._get_tool("check_login_status")
        result = await tool.ainvoke({})
        
        logger.info(f"ç™»å½•çŠ¶æ€: {result}")
        
        # è§£æMCPè¿”å›çš„ç™»å½•çŠ¶æ€
        # MCPè¿”å›æ ¼å¼: [{'type': 'text', 'text': 'âœ… å·²ç™»å½•\nç”¨æˆ·å: xxx...'}]
        is_logged_in = False
        if isinstance(result, list) and len(result) > 0:
            first_item = result[0]
            if isinstance(first_item, dict):
                text = first_item.get('text', '')
                is_logged_in = 'å·²ç™»å½•' in text or 'logged in' in text.lower()
        elif isinstance(result, dict):
            # å…¼å®¹å­—å…¸æ ¼å¼
            is_logged_in = result.get('is_login', False) or result.get('logged_in', False)
        elif isinstance(result, str):
            # å…¼å®¹å­—ç¬¦ä¸²æ ¼å¼
            is_logged_in = 'å·²ç™»å½•' in result or 'logged in' in result.lower()
        
        return {
            "is_login": is_logged_in,
            "raw_result": result
        }
    
    async def get_login_qrcode(self, save_path: str = None) -> Dict:
        """
        è·å–ç™»å½•äºŒç»´ç ï¼ˆç”¨äºæ— æ˜¾ç¤ºå™¨ç¯å¢ƒï¼‰
        
        Args:
            save_path: äºŒç»´ç ä¿å­˜è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›base64ç¼–ç 
        
        Returns:
            åŒ…å«äºŒç»´ç ä¿¡æ¯çš„å­—å…¸
        """
        await self._ensure_connected()
        
        logger.info("è·å–å°çº¢ä¹¦ç™»å½•äºŒç»´ç ...")
        try:
            import asyncio
            tool = self._get_tool("get_login_qrcode")
            
            # æ·»åŠ è¶…æ—¶æ§åˆ¶ï¼ˆ60ç§’ï¼ŒMCP ç”ŸæˆäºŒç»´ç éœ€è¦æ—¶é—´ï¼‰
            logger.info("â±ï¸  ç­‰å¾… MCP æœåŠ¡ç”ŸæˆäºŒç»´ç ï¼ˆå¯èƒ½éœ€è¦ 10-30 ç§’ï¼‰...")
            result = await asyncio.wait_for(
                tool.ainvoke({}),
                timeout=60.0
            )
            
            # å¤„ç†è¿”å›ç»“æœï¼Œæå–base64å›¾ç‰‡æ•°æ®
            qr_base64 = None
            if isinstance(result, list):
                # éå†åˆ—è¡¨æŸ¥æ‰¾imageç±»å‹çš„é¡¹
                for item in result:
                    if isinstance(item, dict) and item.get('type') == 'image':
                        qr_base64 = item.get('base64')
                        break
            elif isinstance(result, dict):
                qr_base64 = result.get('qrcode') or result.get('qr_code') or result.get('image') or result.get('base64')
            
            # ä¿å­˜äºŒç»´ç å›¾ç‰‡
            if save_path and qr_base64:
                import base64
                import os
                
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                save_dir = os.path.dirname(save_path)
                if save_dir:
                    os.makedirs(save_dir, exist_ok=True)
                
                # å¦‚æœæ˜¯data URLæ ¼å¼ï¼Œç§»é™¤å‰ç¼€
                if isinstance(qr_base64, str) and qr_base64.startswith('data:image'):
                    qr_base64 = qr_base64.split(',')[1] if ',' in qr_base64 else qr_base64
                
                # ä¿å­˜å›¾ç‰‡
                if isinstance(qr_base64, str):
                    with open(save_path, 'wb') as f:
                        f.write(base64.b64decode(qr_base64))
                    logger.info(f"âœ… äºŒç»´ç å·²ä¿å­˜åˆ°: {save_path}")
                    
                    # å°†ä¿å­˜è·¯å¾„æ·»åŠ åˆ°ç»“æœä¸­
                    if isinstance(result, dict):
                        result['saved_path'] = save_path
            
            logger.info(f"âœ… è·å–ç™»å½•äºŒç»´ç æˆåŠŸ")
            return result
            
        except asyncio.TimeoutError:
            logger.error("âŒ è·å–ç™»å½•äºŒç»´ç è¶…æ—¶ï¼ˆ60ç§’ï¼‰")
            logger.warning("âš ï¸  MCP æœåŠ¡å¯èƒ½å¡ä½äº†")
            logger.info("ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š")
            logger.info("   1. è¿è¡Œä¿®å¤è„šæœ¬: bash tools/quick_fix_mcp.sh")
            logger.info("   2. æˆ–æ‰‹åŠ¨é‡å¯: pkill -9 -f xiaohongshu-mcp && cd ~/xiaohongshu-mcp && xvfb-run -a go run . -headless=true &")
            return {"error": "timeout"}
        except ValueError:
            logger.warning("âš ï¸  MCPæœåŠ¡ä¸æ”¯æŒ get_login_qrcode å·¥å…·")
            logger.info("è¯·ä½¿ç”¨æµè§ˆå™¨è®¿é—® http://localhost:18060 è¿›è¡Œç™»å½•")
            return {"error": "get_login_qrcode tool not available"}
    
    async def search_feeds(self, keyword: str, limit: int = 10) -> List[Dict]:
        """
        æœç´¢å°çº¢ä¹¦å†…å®¹
        
        Args:
            keyword: æœç´¢å…³é”®è¯
            limit: è¿”å›æ•°é‡é™åˆ¶
        
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        await self._ensure_connected()
        
        logger.info(f"æœç´¢å°çº¢ä¹¦å†…å®¹: {keyword}")
        tool = self._get_tool("search_feeds")
        result = await tool.ainvoke({"keyword": keyword})
        
        # è§£æç»“æœ
        feeds = self._parse_search_result(result, limit)
        logger.info(f"âœ… æ‰¾åˆ° {len(feeds)} ä¸ªç›¸å…³å†…å®¹")
        
        return feeds
    
    async def get_feed_detail(self, feed_id: str, xsec_token: str) -> Dict:
        """
        è·å–å¸–å­è¯¦æƒ…
        
        Args:
            feed_id: å¸–å­ID
            xsec_token: å®‰å…¨ä»¤ç‰Œ
        
        Returns:
            å¸–å­è¯¦æƒ…
        """
        await self._ensure_connected()
        
        logger.info(f"è·å–å¸–å­è¯¦æƒ…: {feed_id}")
        tool = self._get_tool("get_feed_detail")
        result = await tool.ainvoke({
            "feed_id": feed_id,
            "xsec_token": xsec_token
        })
        
        detail = self._parse_feed_detail(result)
        logger.info(f"âœ… è·å–åˆ°å¸–å­: {detail.get('title', 'N/A')[:30]}")
        
        return detail
    
    async def publish_content(self, title: str, content: str, images: List[str], tags: Optional[List[str]] = None) -> Dict:
        """
        å‘å¸ƒå›¾æ–‡å†…å®¹
        
        Args:
            title: æ ‡é¢˜
            content: æ­£æ–‡
            images: å›¾ç‰‡åˆ—è¡¨ï¼ˆæœ¬åœ°è·¯å¾„æˆ–URLï¼‰
            tags: æ ‡ç­¾åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            å‘å¸ƒç»“æœ
        """
        await self._ensure_connected()
        
        logger.info(f"å‘å¸ƒå†…å®¹: {title}")
        logger.info(f"  å›¾ç‰‡æ•°: {len(images)}")
        if tags:
            logger.info(f"  æ ‡ç­¾æ•°: {len(tags)}")
        
        # æ„å»ºå‘å¸ƒå‚æ•°
        publish_params = {
            "title": title,
            "content": content,
            "images": images
        }
        
        # å¦‚æœæœ‰æ ‡ç­¾ï¼Œæ·»åŠ åˆ°contentæœ«å°¾ï¼ˆå°çº¢ä¹¦æ ¼å¼ï¼‰
        if tags:
            tags_str = " ".join(tags)
            publish_params["content"] = f"{content}\n\n{tags_str}"
        
        tool = self._get_tool("publish_content")
        result = await tool.ainvoke(publish_params)
        
        logger.info(f"âœ… å‘å¸ƒæˆåŠŸ")
        return result
    
    def _parse_search_result(self, result, limit: int) -> List[Dict]:
        """è§£ææœç´¢ç»“æœ"""
        feeds = []
        
        logger.info(f"ğŸ” æœç´¢ç»“æœç±»å‹: {type(result)}")
        logger.info(f"ğŸ” æœç´¢ç»“æœå†…å®¹ï¼ˆå‰1000å­—ç¬¦ï¼‰: {str(result)[:1000]}")
        
        # æ ¹æ®å®é™…è¿”å›æ ¼å¼è§£æ
        if isinstance(result, list):
            # å¦‚æœè¿”å›çš„æ˜¯åˆ—è¡¨
            for item in result[:limit]:
                if isinstance(item, dict):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯MCPè¿”å›çš„åŒ…è£…æ ¼å¼
                    if item.get('type') == 'text' and 'text' in item:
                        # è§£æJSONå­—ç¬¦ä¸²
                        import json
                        try:
                            data = json.loads(item['text'])
                            if 'feeds' in data:
                                for feed in data['feeds'][:limit]:
                                    feeds.append({
                                        'feed_id': feed.get('id'),
                                        'xsec_token': feed.get('xsecToken') or feed.get('xsec_token') or ''  # æ³¨æ„é©¼å³°å‘½å
                                    })
                        except:
                            pass
                    else:
                        feeds.append({
                            'feed_id': item.get('id') or item.get('note_id') or item.get('feed_id'),
                            'xsec_token': item.get('xsecToken') or item.get('xsec_token') or item.get('token') or ''  # æ”¯æŒé©¼å³°å‘½å
                        })
                elif isinstance(item, str):
                    # å¦‚æœåˆ—è¡¨é¡¹æ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æ
                    import json
                    try:
                        parsed = json.loads(item)
                        feeds.append({
                            'feed_id': parsed.get('id') or parsed.get('note_id'),
                            'xsec_token': parsed.get('xsec_token') or ''
                        })
                    except:
                        pass
        
        elif isinstance(result, dict):
            # å¦‚æœè¿”å›çš„æ˜¯å­—å…¸
            items = result.get('items') or result.get('notes') or result.get('feeds') or []
            for item in items[:limit]:
                feeds.append({
                    'feed_id': item.get('id') or item.get('note_id') or item.get('feed_id'),
                    'xsec_token': item.get('xsec_token') or item.get('token') or ''
                })
        
        elif isinstance(result, str):
            # å¦‚æœè¿”å›çš„æ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•æå–ä¿¡æ¯
            import re
            import json
            
            # å°è¯•è§£æä¸ºJSON
            try:
                parsed = json.loads(result)
                return self._parse_search_result(parsed, limit)
            except:
                pass
            
            # æ­£åˆ™æå–
            feed_ids = re.findall(r'(?:feed_id|note_id|id)["\s:]+([a-zA-Z0-9]+)', result)
            tokens = re.findall(r'xsec_token["\s:]+([a-zA-Z0-9_-]+)', result)
            
            for i, feed_id in enumerate(feed_ids[:limit]):
                token = tokens[i] if i < len(tokens) else ''
                feeds.append({
                    'feed_id': feed_id,
                    'xsec_token': token
                })
        
        logger.info(f"è§£æå‡º {len(feeds)} ä¸ªå¸–å­")
        return feeds
    
    def _parse_feed_detail(self, result) -> Dict:
        """è§£æå¸–å­è¯¦æƒ…"""
        logger.info(f"ğŸ” å¸–å­è¯¦æƒ…åŸå§‹æ•°æ®ç±»å‹: {type(result)}")
        logger.info(f"ğŸ” å¸–å­è¯¦æƒ…åŸå§‹æ•°æ®ï¼ˆå‰3000å­—ç¬¦ï¼‰: {str(result)[:3000]}")
        
        detail = {
            'title': '',
            'content': '',
            'images': [],
            'tags': []
        }
        
        # æ ¹æ®å®é™…è¿”å›æ ¼å¼è§£æ
        if isinstance(result, list) and len(result) > 0:
            # MCPå¯èƒ½è¿”å›åˆ—è¡¨æ ¼å¼
            first_item = result[0]
            if isinstance(first_item, dict) and first_item.get('type') == 'text':
                # è§£æJSONå­—ç¬¦ä¸²
                import json
                try:
                    data = json.loads(first_item['text'])
                    
                    # æ•°æ®ç»“æ„æ˜¯åµŒå¥—çš„ï¼šdata.note.xxx
                    note_data = data.get('data', {}).get('note', {})
                    
                    # æå–æ ‡é¢˜
                    detail['title'] = note_data.get('title', '')
                    detail['content'] = note_data.get('desc', '')
                    
                    # æå–å›¾ç‰‡ï¼ˆä»imageListä¸­è·å–urlDefaultï¼‰
                    if 'imageList' in note_data:
                        detail['images'] = [
                            img.get('urlDefault') or img.get('url') or img.get('urlPre') 
                            for img in note_data['imageList'] 
                            if img.get('urlDefault') or img.get('url') or img.get('urlPre')
                        ]
                    
                    # æå–æ ‡ç­¾ï¼ˆä»descä¸­æå–#è¯é¢˜ï¼‰
                    import re
                    tags = re.findall(r'#([^#\[]+)\[è¯é¢˜\]', note_data.get('desc', ''))
                    detail['tags'] = [f"#{tag.strip()}" for tag in tags]
                    
                    logger.info(f"âœ… è§£æå‡ºæ ‡é¢˜: {detail['title']}")
                    logger.info(f"âœ… è§£æå‡º {len(detail['images'])} å¼ å›¾ç‰‡")
                    logger.info(f"âœ… è§£æå‡º {len(detail['tags'])} ä¸ªæ ‡ç­¾")
                except Exception as e:
                    logger.error(f"âŒ JSONè§£æå¤±è´¥: {e}")
        
        elif isinstance(result, str):
            import re
            
            # æå–æ ‡é¢˜
            title_match = re.search(r'title["\s:]+([^\n"]+)', result)
            if title_match:
                detail['title'] = title_match.group(1).strip()
            
            # æå–å›¾ç‰‡URL
            image_urls = re.findall(r'https?://[^\s"]+\.(?:jpg|jpeg|png|webp)', result)
            detail['images'] = image_urls
            
            # æå–æ ‡ç­¾
            tags = re.findall(r'#([^\s#]+)', result)
            detail['tags'] = [f"#{tag}" for tag in tags]
        
        return detail


def run_async(coro):
    """è¿è¡Œå¼‚æ­¥å‡½æ•°çš„åŒæ­¥åŒ…è£…"""
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
    
    return loop.run_until_complete(coro)

